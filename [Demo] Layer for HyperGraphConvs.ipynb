{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 範例資料"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DADs.shape = (num_K, num_nodes, num_nodes)  #事先計算好 #非稀疏張量運算\n",
    "\n",
    "X.shape = (batch_size, num_nodes, num_Fin) #非稀疏張量運算\n",
    "\n",
    "W.shape = (num_K, num_Fin, num_Fout)\n",
    "\n",
    "b.shape = (num_Fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T16:19:07.763368Z",
     "start_time": "2021-05-09T16:19:03.561392Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj:\n",
      "[[0. 1. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n",
      "\n",
      "H=adj+I:\n",
      "[[1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0.]\n",
      " [0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 1.]]\n",
      "\n",
      "hyperedges = [[0, 1], [0, 1, 2], [1, 2, 3, 4], [2, 3], [2, 4]]\n",
      "\n",
      "H=\n",
      "[[1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0.]\n",
      " [0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 1.]]\n",
      "\n",
      "DvH_WDe_HDvs: shape=(num_K, num_nodes, num_nodes)=(1, 5, 5) type=<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[[[0.4166667  0.34020692 0.11785113 0.         0.        ]\n",
      "  [0.34020692 0.3611111  0.16839384 0.10206208 0.10206208]\n",
      "  [0.11785113 0.16839384 0.39583334 0.26516503 0.26516503]\n",
      "  [0.         0.10206208 0.26516503 0.375      0.125     ]\n",
      "  [0.         0.10206208 0.26516503 0.125      0.375     ]]]\n",
      "\n",
      "X: shape=(batch_size, num_nodes, num_Fin)=(2, 5, 3) type=<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[[[ 0.  1.  2.]\n",
      "  [ 3.  4.  5.]\n",
      "  [ 6.  7.  8.]\n",
      "  [ 9. 10. 11.]\n",
      "  [12. 13. 14.]]\n",
      "\n",
      " [[15. 16. 17.]\n",
      "  [18. 19. 20.]\n",
      "  [21. 22. 23.]\n",
      "  [24. 25. 26.]\n",
      "  [27. 28. 29.]]]\n",
      "\n",
      "W: shape=(num_K, num_Fin, num_Fout)=(1, 3, 4) type=<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[[[ 0.  1.  2.  3.]\n",
      "  [ 4.  5.  6.  7.]\n",
      "  [ 8.  9. 10. 11.]]]\n",
      "\n",
      "b: shape=(num_Fout)=(4,) type=<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[0. 1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from math_graph import get_adj\n",
    "from math_hypergraph import get_sp_H, get_hyperedges\n",
    "from math_hypergraph import get_sp_DvH_WDe_HDv\n",
    "\n",
    "num_nodes = 5\n",
    "edges = [(0, 1), (1, 2), (2, 3), (2, 4)]\n",
    "# 產生 adj\n",
    "adj = get_adj(edges, num_nodes)\n",
    "print(f\"adj:\\n{adj.toarray()}\\n\")\n",
    "\n",
    "# 產生 H = adj + I\n",
    "H = adj + sp.eye(adj.shape[0])\n",
    "print(f\"H=adj+I:\\n{H.toarray()}\\n\")\n",
    "\n",
    "# H 產生 hyperedges\n",
    "hyperedges = get_hyperedges(H)\n",
    "print(f\"hyperedges = {hyperedges}\\n\")\n",
    "\n",
    "# hyperedges 產生 H\n",
    "H = get_sp_H(hyperedges, num_nodes)\n",
    "print(f\"H=\\n{H.toarray()}\\n\")\n",
    "\n",
    "\n",
    "# 產生 Dv@H @ W@De @ H.T@Dv\n",
    "DvH_WDe_HDv = get_sp_DvH_WDe_HDv(H).toarray()\n",
    "DvH_WDe_HDv = tf.convert_to_tensor(DvH_WDe_HDv, dtype='float32')\n",
    "DvH_WDe_HDvs = tf.expand_dims(DvH_WDe_HDv, 0)\n",
    "print(f\"DvH_WDe_HDvs: shape=(num_K, num_nodes, num_nodes)=\",end='')\n",
    "print(f\"{DvH_WDe_HDvs.shape} type={type(DvH_WDe_HDvs)}\\n{DvH_WDe_HDvs.numpy()}\\n\")\n",
    "\n",
    "batch_size = 2\n",
    "num_Fin = 3\n",
    "X = np.arange(batch_size*num_nodes*num_Fin).reshape([batch_size, num_nodes, num_Fin])\n",
    "X = tf.convert_to_tensor(X, dtype='float32')\n",
    "print(f\"X: shape=(batch_size, num_nodes, num_Fin)={X.shape} type={type(X)}\\n{X.numpy()}\\n\")\n",
    "\n",
    "num_Fout = 4\n",
    "num_K = DvH_WDe_HDvs.shape[0]\n",
    "W = np.arange(num_Fin*num_Fout).reshape([num_K, num_Fin, num_Fout])\n",
    "W = tf.convert_to_tensor(W, dtype='float32')\n",
    "print(f\"W: shape=(num_K, num_Fin, num_Fout)={W.shape} type={type(W)}\\n{W.numpy()}\\n\")\n",
    "\n",
    "\n",
    "b = np.arange(num_Fout).reshape([num_Fout])\n",
    "b = tf.convert_to_tensor(b, dtype='float32')\n",
    "print(f\"b: shape=(num_Fout)={b.shape} type={type(b)}\\n{b.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 張量運算說明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T16:19:08.210668Z",
     "start_time": "2021-05-09T16:19:07.768354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: DvH_WDe_HDvs=(num_K, num_nodes, #num_nodes)=(1, 5, 5)\n",
      "shape: X=(batch_size, #num_nodes', num_Fin)=(2, 5, 3)\n",
      "\n",
      "shape: DvH_WDe_HDvs @ X = DvH_WDe_HDvsX = (batch_size, num_Fin, num_K, num_nodes)=(2, 3, 1, 5)\n",
      "[[[[ 1.7277277  4.237      8.448647   6.7721763  7.5221763]]\n",
      "\n",
      "  [[ 2.6024523  5.310836   9.6610565  7.639404   8.389403 ]]\n",
      "\n",
      "  [[ 3.4771771  6.384672  10.873465   8.506631   9.256631 ]]]\n",
      "\n",
      "\n",
      " [[[14.8485985 20.34454   26.634771  19.780584  20.530582 ]]\n",
      "\n",
      "  [[15.723323  21.418377  27.847183  20.64781   21.39781  ]]\n",
      "\n",
      "  [[16.59805   22.492214  29.05959   21.515038  22.265038 ]]]]\n",
      "\n",
      "\n",
      "shape: DvH_WDe_HDvsX=(batch_size, #num_Fin, #num_K, num_nodes)=(2, 3, 1, 5)\n",
      "shape: W=(#num_K, #num_Fin, num_Fout)=(1, 3, 4)\n",
      "\n",
      "shape: DvH_WDe_HDvsX @ W = DvH_WDe_HDvsXW = (batch_size, num_nodes, num_Fout)=(2, 5, 4)\n",
      "[[[ 38.227226  46.034584  53.84194   61.649296]\n",
      "  [ 72.320724  88.253235 104.18574  120.11824 ]\n",
      "  [125.63194  154.61511  183.59828  212.58145 ]\n",
      "  [ 98.610664 121.52887  144.44708  167.3653  ]\n",
      "  [107.61066  132.77887  157.94708  183.1153  ]]\n",
      "\n",
      " [[195.67769  242.84766  290.01764  337.1876  ]\n",
      "  [265.6112   329.86636  394.1215   458.3766  ]\n",
      "  [343.86545  427.40698  510.94855  594.4901  ]\n",
      "  [254.71155  316.65497  378.5984   440.5418  ]\n",
      "  [263.71155  327.90497  392.0984   456.2918  ]]]\n",
      "\n",
      "\n",
      "shape: DvH_WDe_HDvsXW+b=(2, 5, 4)\n",
      "[[[ 38.227226  47.034584  55.84194   64.64929 ]\n",
      "  [ 72.320724  89.253235 106.18574  123.11824 ]\n",
      "  [125.63194  155.61511  185.59828  215.58145 ]\n",
      "  [ 98.610664 122.52887  146.44708  170.3653  ]\n",
      "  [107.61066  133.77887  159.94708  186.1153  ]]\n",
      "\n",
      " [[195.67769  243.84766  292.01764  340.1876  ]\n",
      "  [265.6112   330.86636  396.1215   461.3766  ]\n",
      "  [343.86545  428.40698  512.94855  597.4901  ]\n",
      "  [254.71155  317.65497  380.5984   443.5418  ]\n",
      "  [263.71155  328.90497  394.0984   459.2918  ]]]\n"
     ]
    }
   ],
   "source": [
    "# DvH_WDe_HDvs @ X\n",
    "print(f\"shape: DvH_WDe_HDvs=(num_K, num_nodes, #num_nodes)={DvH_WDe_HDvs.shape}\")\n",
    "print(f\"shape: X=(batch_size, #num_nodes', num_Fin)={X.shape}\\n\")\n",
    "\n",
    "DvH_WDe_HDvsX = tf.tensordot(X, DvH_WDe_HDvs, axes=([1], [-1]))\n",
    "print(f\"shape: DvH_WDe_HDvs @ X = DvH_WDe_HDvsX = \", end='')\n",
    "print(f\"(batch_size, num_Fin, num_K, num_nodes)\", end='')\n",
    "print(f\"={DvH_WDe_HDvsX.shape}\\n{DvH_WDe_HDvsX.numpy()}\\n\\n\")\n",
    "\n",
    "# DvH_WDe_HDvs@X @ W\n",
    "print(f\"shape: DvH_WDe_HDvsX=(batch_size, #num_Fin, #num_K, num_nodes)={DvH_WDe_HDvsX.shape}\")\n",
    "print(f\"shape: W=(#num_K, #num_Fin, num_Fout)={W.shape}\\n\")\n",
    "\n",
    "DvH_WDe_HDvsXW = tf.tensordot(DvH_WDe_HDvsX, W, axes=([1, 2], [1, 0]))\n",
    "print(f\"shape: DvH_WDe_HDvsX @ W = DvH_WDe_HDvsXW = (batch_size, num_nodes, num_Fout)\", end='')\n",
    "print(f\"={DvH_WDe_HDvsXW.shape}\\n{DvH_WDe_HDvsXW.numpy()}\\n\\n\")\n",
    "\n",
    "# DvH_WDe_HDvs@X@W + b\n",
    "output = tf.add(DvH_WDe_HDvsXW, b)\n",
    "print(f\"shape: DvH_WDe_HDvsXW+b={output.shape}\\n{output.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphConvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T16:19:08.225629Z",
     "start_time": "2021-05-09T16:19:08.211668Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaseDense(tf.keras.layers.Dense):\n",
    "    def add_weight_kernel(self, shape, name='kernel', trainable=True):\n",
    "        return self.add_weight(name=name,\n",
    "                               shape=shape,\n",
    "                               trainable=trainable,\n",
    "                               initializer=self.kernel_initializer,\n",
    "                               regularizer=self.kernel_regularizer,\n",
    "                               constraint=self.kernel_constraint,\n",
    "                               dtype=self.dtype)\n",
    "\n",
    "    def add_weight_bias(self, shape, name='bias', trainable=True):\n",
    "        return self.add_weight(name=name,\n",
    "                               shape=shape,\n",
    "                               trainable=trainable,\n",
    "                               initializer=self.bias_initializer,\n",
    "                               regularizer=self.bias_regularizer,\n",
    "                               constraint=self.bias_constraint,\n",
    "                               dtype=self.dtype)\n",
    "\n",
    "class HyperGraphConvs(BaseDense):\n",
    "    def __init__(self, units, DvH_WDe_HDvs, name=None, **kwargs):\n",
    "        super(HyperGraphConvs, self).__init__(units=units, name=name, **kwargs)\n",
    "        self.DvH_WDe_HDvs = tf.convert_to_tensor(DvH_WDe_HDvs)\n",
    "        self.num_K = len(DvH_WDe_HDvs)  # K\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.num_Fin = input_shape[-1]  # Fin\n",
    "        self.num_Fout = self.units  # Fout\n",
    "        self.kernel = self.add_weight_kernel([self.num_K, self.num_Fin, self.num_Fout])\n",
    "        self.bias = self.add_weight_bias([self.num_Fout,]) if self.use_bias else None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X = tf.tensordot(inputs, self.DvH_WDe_HDvs, axes=([1], [-1]))\n",
    "        X = tf.tensordot(X, self.kernel, axes=([1, 2], [1, 0]))\n",
    "        if self.use_bias:\n",
    "            X = tf.add(X, self.bias)\n",
    "        outputs = self.activation(X)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T16:19:08.257547Z",
     "start_time": "2021-05-09T16:19:08.226627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 4), dtype=float32, numpy=\n",
       "array([[[ -3.1023996 ,   0.10740995,  -0.41523838,  -0.17583299],\n",
       "        [ -6.4483604 ,  -0.19162321,  -1.4694877 ,   0.3747816 ],\n",
       "        [-11.852545  ,  -0.7766206 ,  -3.321363  ,   1.4461269 ],\n",
       "        [ -9.387391  ,  -0.6669445 ,  -2.7063556 ,   1.2378678 ],\n",
       "        [-10.32304   ,  -0.7816007 ,  -3.046525  ,   1.4472156 ]],\n",
       "\n",
       "       [[-19.471102  ,  -1.8984432 ,  -6.3663387 ,   3.4866037 ],\n",
       "        [-26.543026  ,  -2.6540623 ,  -8.775222  ,   4.8708878 ],\n",
       "        [-34.54031   ,  -3.5568247 , -11.56986   ,   6.5224323 ],\n",
       "        [-25.615791  ,  -2.6556053 ,  -8.606447  ,   4.8689137 ],\n",
       "        [-26.55144   ,  -2.7702608 ,  -8.946617  ,   5.0782604 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from layer_hgconv import HyperGraphConvs\n",
    "\n",
    "## 產生 H [方法一] 從無向圖轉換\n",
    "# H = adj + sp.eye(adj.shape[0])\n",
    "\n",
    "## 產生 H [方法二] 使用超邊建構\n",
    "# H = get_sp_H(hyperedges, num_nodes)\n",
    "\n",
    "## 產生 DvH_WDe_HDvs\n",
    "# DvH_WDe_HDv = get_sp_DvH_WDe_HDv(H).toarray()\n",
    "# DvH_WDe_HDv = tf.convert_to_tensor(DvH_WDe_HDv, dtype='float32')\n",
    "# DvH_WDe_HDvs = tf.expand_dims(DvH_WDe_HDv, 0)\n",
    "\n",
    "HyperGraphConvs(units=num_Fout, DvH_WDe_HDvs=DvH_WDe_HDvs, use_bias=True)(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
