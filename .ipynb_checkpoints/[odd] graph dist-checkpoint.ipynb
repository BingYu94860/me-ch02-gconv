{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T15:27:08.403862Z",
     "start_time": "2021-06-17T15:27:06.485933Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "def get_adj(edges: list, num_nodes: int):\n",
    "    e_rows, e_cols = np.array(edges, dtype=np.int).transpose()\n",
    "    values = np.ones(shape=(len(e_rows), ), dtype=np.float32)\n",
    "    adj = sp.coo_matrix((values, (e_rows, e_cols)),\n",
    "                        shape=[num_nodes, num_nodes])\n",
    "    # triu adj --> adj\n",
    "    adj.setdiag(0)\n",
    "    bigger = adj.T > adj\n",
    "    adj = adj - adj.multiply(bigger) + adj.T.multiply(bigger)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T15:26:17.967800Z",
     "start_time": "2021-06-17T15:26:17.937882Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "W = get_adj([(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (6, 7), (7, 8), (8, 9)], 10).toarray()\n",
    "\n",
    "W[W == 0] = -1\n",
    "W = W + np.identity(W.shape[0])\n",
    "W[W == -1] = float('inf')\n",
    "\n",
    "# W[np.isinf(W)] = -1\n",
    "# W[W == -1] = float('inf')\n",
    "\n",
    "print(W)\n",
    "W = np.min(np.expand_dims(W, 0)+np.expand_dims(W, 2), 1)\n",
    "print(W)\n",
    "W = np.min(np.expand_dims(W, 0)+np.expand_dims(W, 2), 1)\n",
    "print(W)\n",
    "W = np.min(np.expand_dims(W, 0)+np.expand_dims(W, 2), 1)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T15:26:18.094086Z",
     "start_time": "2021-06-17T15:26:18.080095Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "for iw in W:\n",
    "    iw = iw.reshape([-1,1])+W\n",
    "    # print(iw)\n",
    "    iw = np.min(iw, axis=0)\n",
    "    print(iw)\n",
    "\n",
    "print()\n",
    "np.min(np.expand_dims(W, 0)+np.expand_dims(W, 2), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T15:26:24.247585Z",
     "start_time": "2021-06-17T15:26:24.235618Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "for iw in W:\n",
    "    iw = iw+W\n",
    "    #print(iw)\n",
    "    iw = np.min(iw, axis=1)\n",
    "    print(iw)\n",
    "\n",
    "print()\n",
    "np.min(np.expand_dims(W, 0)+np.expand_dims(W, 1), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T18:37:39.166863Z",
     "start_time": "2021-05-16T18:37:38.495774Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "W = get_adj([(0, 1), (1, 2), (2, 3), (3, 4), (4, 5),  (6, 7), (7, 8), (8, 9)], 10).toarray()\n",
    "\n",
    "W[W == 0] = -1\n",
    "W = W + np.identity(W.shape[0])\n",
    "W[W == -1] = float('inf')\n",
    "W = W.astype('float32')\n",
    "\n",
    "W = tf.convert_to_tensor(W)\n",
    "\n",
    "print(W)\n",
    "#W = tf.reduce_min(tf.expand_dims(W, 0)+tf.expand_dims(W, 2), 1)\n",
    "W = tf.stack([tf.reduce_min(iw+W, 0) for iw in tf.expand_dims(W, 2)])\n",
    "print(W)\n",
    "#W = tf.reduce_min(tf.expand_dims(W, 0)+tf.expand_dims(W, 2), 1)\n",
    "W = tf.stack([tf.reduce_min(iw+W, 0) for iw in tf.expand_dims(W, 2)])\n",
    "print(W)\n",
    "#W = tf.reduce_min(tf.expand_dims(W, 0)+tf.expand_dims(W, 2), 1)\n",
    "W = tf.stack([tf.reduce_min(iw+W, 0) for iw in tf.expand_dims(W, 2)])\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T18:37:39.198240Z",
     "start_time": "2021-05-16T18:37:39.168861Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def dist_W(dW, K=None):\n",
    "    # 疊代 K次，計算節點與節點之間最點距離\n",
    "    # dW 為 graph的距離矩陣\n",
    "    # dw的值 為 [0~inf)\n",
    "    # dw.shape = [num_N, num_N]\n",
    "    num_N = dW.shape[0]\n",
    "    max_K = int(np.ceil(np.log2(num_N)))\n",
    "    #print(f'max_K={max_K}, K={K}')\n",
    "    if K is not None and K < max_K:\n",
    "        max_K = K\n",
    "    for i in range(max_K):\n",
    "        dW_odd = dW\n",
    "        dW = tf.expand_dims(dW, 0)+tf.expand_dims(dW, 2) # [N,N,N]\n",
    "        dW = tf.reduce_min(dW, 1)\n",
    "        if tf.math.reduce_all(tf.equal(dW, dW_odd)):\n",
    "            #print('break')\n",
    "            break\n",
    "        #print(f'{i} {dW}')\n",
    "    return dW\n",
    "\n",
    "def dist_H_from_adj(adj, N=None, K=None):\n",
    "    W = np.array(adj, 'float32')\n",
    "    W[W == 0] = float('inf')\n",
    "    np.fill_diagonal(W, 0)\n",
    "    W = tf.convert_to_tensor(W)\n",
    "    # dW 計算節點與節點 的距離\n",
    "    dW = dist_W(W, K=K)\n",
    "    print(dW)\n",
    "    if N is None:\n",
    "        dW = tf.cast(tf.logical_not(tf.math.is_inf(dW)), 'float32')\n",
    "    else:\n",
    "        dW = tf.cast(tf.less_equal(dW, N), 'float32')\n",
    "    H = sp.coo_matrix(dW.numpy())\n",
    "    return H\n",
    "\n",
    "adj = get_adj([(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5,6), (6, 7), (7, 8), (8, 9)], 10).toarray()\n",
    "dist_H_from_adj(adj, 3, 1).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T15:08:25.883413Z",
     "start_time": "2021-06-17T15:08:25.804625Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def tf_sparse_add_zero_eye(sp_a):  # 維持 對角線 元素存在\n",
    "    In = tf.sparse.eye(sp_a.shape[0], dtype=sp_a.dtype)\n",
    "    return tf.sparse.add(sp_a, In * 0)\n",
    "\n",
    "\n",
    "def tf_sparse_add_intersection(sp_a, sp_b):  # 只相加交集部分\n",
    "    sp_ab = tf.sparse.add(sp_a, sp_b)\n",
    "    a = tf.sparse.map_values(tf.ones_like, sp_a)\n",
    "    b = tf.sparse.map_values(tf.ones_like, sp_b)\n",
    "    ab = tf.sparse.map_values(tf.ones_like, sp_ab)  # union(a, b)\n",
    "    _a = tf.sparse.add(ab, a * -1)\n",
    "    _b = tf.sparse.add(ab, b * -1)\n",
    "    a_b = tf.sparse.add(_a, _b)  # union(a, b) - intersection(a, b)\n",
    "    _ab_ = tf.sparse.add(ab, a_b * -1)  # intersection(a, b)\n",
    "    to_retain = tf.cast(_ab_.values, 'bool')\n",
    "    return tf.sparse.retain(sp_ab, to_retain)\n",
    "\n",
    "\n",
    "def one_dim_SparseTensor(unique_indices, values, shape):\n",
    "    # SparseTensor 需要 2 維 才能建立\n",
    "    idx = tf.zeros_like(unique_indices, dtype='int64')\n",
    "    indices = tf.stack([idx, unique_indices], -1)\n",
    "    x = tf.sparse.SparseTensor(indices, values, [1] + shape)\n",
    "    return tf.sparse.reshape(x, shape)  # 將成 1 維 SparseTensor\n",
    "\n",
    "\n",
    "def tf_sparse_reduce_min(sp_a, axis=-1):\n",
    "    dim = sp_a.shape[axis]\n",
    "    shape = np.delete(sp_a.shape, axis)\n",
    "    # 將 axis 移到最後\n",
    "    perm = list(range(len(sp_a.shape)))\n",
    "    perm.insert(-1, perm.pop())\n",
    "    sp_a = tf.sparse.transpose(sp_a, perm=perm)\n",
    "    # reduce_min(sp_a, axis=-1)\n",
    "    a = tf.sparse.reshape(sp_a, [-1, dim])\n",
    "    indices = a.indices[:, 0]\n",
    "    a = tf.math.segment_min(a.values, indices)\n",
    "    a = tf.sparse.from_dense(a)\n",
    "    # 補上因計算而消失的零元素\n",
    "    unique_indices, _ = tf.unique(indices)\n",
    "    values = tf.zeros_like(unique_indices, a.dtype)\n",
    "    zeros = one_dim_SparseTensor(unique_indices, values, a.shape)\n",
    "    a = tf.sparse.add(a, zeros)\n",
    "    return tf.sparse.reshape(a, shape)\n",
    "\n",
    "\n",
    "W = get_adj([(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (6, 7), (7, 8), (8, 9)],\n",
    "            10).toarray()\n",
    "W = W.astype('float32')\n",
    "W = tf.convert_to_tensor(W)\n",
    "W = tf.sparse.from_dense(W)\n",
    "\n",
    "W = tf_sparse_add_zero_eye(W)  # 維持 對角線 元素存在\n",
    "tf.sparse.to_dense(W, default_value=math.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T15:05:28.788604Z",
     "start_time": "2021-06-17T15:05:28.759682Z"
    }
   },
   "outputs": [],
   "source": [
    "A = tf.sparse.expand_dims(W, 2) # [N1, N2, 1]\n",
    "B = tf.sparse.expand_dims(W, 0) # [1, N1, N2]\n",
    "As = tf.sparse.concat(2, [A]*B.shape[2])\n",
    "Bs = tf.sparse.concat(0, [B]*A.shape[0])\n",
    "AB = tf_sparse_add_intersection(As, Bs) # 只相加交集部分\n",
    "W = tf_sparse_reduce_min(AB, axis=1)\n",
    "\n",
    "tf.sparse.to_dense(W, default_value=math.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T15:05:45.133527Z",
     "start_time": "2021-06-17T15:05:45.095627Z"
    }
   },
   "outputs": [],
   "source": [
    "A = tf.sparse.expand_dims(W, 2) # [N1, N2, 1]\n",
    "B = tf.sparse.expand_dims(W, 0) # [1, N1, N2]\n",
    "As = tf.sparse.concat(2, [A]*B.shape[2])\n",
    "Bs = tf.sparse.concat(0, [B]*A.shape[0])\n",
    "AB = tf_sparse_add_intersection(As, Bs) # 只相加交集部分\n",
    "W = tf_sparse_reduce_min(AB, axis=1)\n",
    "\n",
    "tf.sparse.to_dense(W, default_value=math.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T11:52:18.854101Z",
     "start_time": "2021-06-17T11:52:18.826174Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def tf_sp_intersection(sp_a, sp_b):\n",
    "    a = tf.sparse.expand_dims(sp_a, -1)\n",
    "    b = tf.sparse.expand_dims(sp_b, -1)\n",
    "    a = tf.sparse.map_values(tf.ones_like, a)\n",
    "    b = tf.sparse.map_values(tf.ones_like, b)\n",
    "    a = tf.cast(a, 'int32')\n",
    "    b = tf.cast(b, 'int32')\n",
    "    ab = tf.sets.intersection(a, b)\n",
    "    ab = tf.sparse.reshape(ab, ab.shape[:-1])\n",
    "    sp_ab = tf.cast(ab, 'float32')\n",
    "    return sp_ab\n",
    "\n",
    "sp_ab = tf_sp_intersection(As, Bs)\n",
    "tf.sparse.to_dense(sp_ab, default_value=math.inf)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T15:07:54.172741Z",
     "start_time": "2021-06-17T15:07:54.162768Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T15:59:26.195347Z",
     "start_time": "2021-06-17T15:59:26.162437Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# from math_graph_knn import get_adj, get_dW\n",
    "# from math_graph_knn import get_adj, get_H_run_KNeighbors\n",
    "# from math_graph_knn import get_adj, get_H_run_RadiusNeighbors\n",
    "#==========#==========#==========#==========#==========#==========#==========#\n",
    "\n",
    "\n",
    "def tf_sparse_add_zero_eye(sp_a):  # 維持 對角線 元素存在\n",
    "    In = tf.sparse.eye(sp_a.shape[0], dtype=sp_a.dtype)\n",
    "    return tf.sparse.add(sp_a, In * 0)\n",
    "\n",
    "\n",
    "def tf_sparse_add_intersection(sp_a, sp_b):  # 只相加交集部分\n",
    "    sp_ab = tf.sparse.add(sp_a, sp_b)\n",
    "    a = tf.sparse.map_values(tf.ones_like, sp_a)\n",
    "    b = tf.sparse.map_values(tf.ones_like, sp_b)\n",
    "    ab = tf.sparse.map_values(tf.ones_like, sp_ab)  # union(a, b)\n",
    "    _a = tf.sparse.add(ab, a * -1)\n",
    "    _b = tf.sparse.add(ab, b * -1)\n",
    "    a_b = tf.sparse.add(_a, _b)  # union(a, b) - intersection(a, b)\n",
    "    _ab_ = tf.sparse.add(ab, a_b * -1)  # intersection(a, b)\n",
    "    to_retain = tf.cast(_ab_.values, 'bool')\n",
    "    return tf.sparse.retain(sp_ab, to_retain)\n",
    "\n",
    "\n",
    "def one_dim_SparseTensor(unique_indices, values, shape):\n",
    "    # SparseTensor 需要 2 維 才能建立\n",
    "    idx = tf.zeros_like(unique_indices, dtype='int64')\n",
    "    indices = tf.stack([idx, unique_indices], -1)\n",
    "    x = tf.sparse.SparseTensor(indices, values, [1] + shape)\n",
    "    return tf.sparse.reshape(x, shape)  # 將成 1 維 SparseTensor\n",
    "\n",
    "\n",
    "def tf_sparse_reduce_min(sp_a, axis=-1):\n",
    "    dim = sp_a.shape[axis]\n",
    "    shape = np.delete(sp_a.shape, axis)\n",
    "    # 將 axis 移到最後\n",
    "    perm = list(range(len(sp_a.shape)))\n",
    "    perm.insert(-1, perm.pop())\n",
    "    sp_a = tf.sparse.transpose(sp_a, perm=perm)\n",
    "    # reduce_min(sp_a, axis=-1)\n",
    "    a = tf.sparse.reshape(sp_a, [-1, dim])\n",
    "    indices = a.indices[:, 0]\n",
    "    a = tf.math.segment_min(a.values, indices)\n",
    "    a = tf.sparse.from_dense(a)\n",
    "    # 補上因計算而消失的零元素\n",
    "    unique_indices, _ = tf.unique(indices)\n",
    "    values = tf.zeros_like(unique_indices, a.dtype)\n",
    "    zeros = one_dim_SparseTensor(unique_indices, values, a.shape)\n",
    "    a = tf.sparse.add(a, zeros)\n",
    "    return tf.sparse.reshape(a, shape)\n",
    "\n",
    "\n",
    "#==========#==========#==========#==========#==========#==========#==========#\n",
    "\n",
    "\n",
    "def get_adj(edges: list, num_nodes: int):\n",
    "    e_rows, e_cols = np.array(edges, dtype=np.int).transpose()\n",
    "    values = np.ones(shape=(len(e_rows), ), dtype=np.float32)\n",
    "    adj = sp.coo_matrix((values, (e_rows, e_cols)),\n",
    "                        shape=[num_nodes, num_nodes])\n",
    "    # triu adj --> adj\n",
    "    adj.setdiag(0)\n",
    "    bigger = adj.T > adj\n",
    "    adj = adj - adj.multiply(bigger) + adj.T.multiply(bigger)\n",
    "    return adj\n",
    "\n",
    "\n",
    "# 原型 核心\n",
    "def tf_sparse_dist_W(dW, num_loop=None, batch_size=None, verbose=False):\n",
    "    num_nodes = dW.shape[0]\n",
    "    # 計算估計 max loop\n",
    "    max_loop = int(np.ceil(np.log2(num_nodes)))\n",
    "    if num_loop is not None:\n",
    "        max_loop = min(num_loop, max_loop)\n",
    "    # 設定 預設 batch_size\n",
    "    if batch_size is None:\n",
    "        if num_nodes >= 1000:\n",
    "            batch_size = 10\n",
    "        else:\n",
    "            batch_size = num_nodes\n",
    "    if verbose:\n",
    "        print(f'max_loop={max_loop}, batch_size={batch_size}')\n",
    "    # 迭代 max_loop 次\n",
    "    for i_loop in range(max_loop):\n",
    "        dW_odd = dW\n",
    "\n",
    "        A = tf.sparse.expand_dims(dW, 2)  # [N1, N2, 1]\n",
    "        B = tf.sparse.expand_dims(dW, 0)  # [1, N1, N2]\n",
    "        As = tf.sparse.concat(2, [A] * B.shape[2])\n",
    "        Bs = tf.sparse.concat(0, [B] * A.shape[0])\n",
    "        AB = tf_sparse_add_intersection(As, Bs)  # 只相加交集部分\n",
    "        dW = tf_sparse_reduce_min(AB, axis=1)\n",
    "\n",
    "        qdW = tf.sparse.to_dense(dW, default_value=math.inf)\n",
    "        qdW_odd = tf.sparse.to_dense(dW_odd, default_value=math.inf)\n",
    "        # 檢查如果 dW 和 dW_odd 則 提前停止\n",
    "        if tf.math.reduce_all(tf.equal(qdW, qdW_odd)):\n",
    "            break\n",
    "        if verbose:\n",
    "            print(f'run {i_loop}/{max_loop}')\n",
    "            print(f'{dW}')\n",
    "    return dW\n",
    "\n",
    "\n",
    "#==========#==========#==========#==========#==========#==========#==========#\n",
    "\n",
    "\n",
    "# 包裝 直接用\n",
    "def get_dW(adj, num_loop=None, batch_size=1, verbose=False):\n",
    "    # 轉成 稀疏張量\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    adj = adj.toarray().astype('float32')\n",
    "    adj = tf.convert_to_tensor(adj)\n",
    "    dW = tf.sparse.from_dense(adj)\n",
    "    # 維持 對角線 元素存在 (補0)\n",
    "    dW = tf_sparse_add_zero_eye(dW)\n",
    "    # 計算 距離矩陣\n",
    "    dW = tf_sparse_dist_W(dW, num_loop, batch_size, verbose=verbose)\n",
    "    return dW\n",
    "\n",
    "\n",
    "#==========#==========#==========#==========#==========#==========#==========#\n",
    "\n",
    "\n",
    "def tf_KNN_for_dW(dW, K=3):\n",
    "    num_nodes = dW.shape[0]\n",
    "    rr = tf.tile(tf.expand_dims(tf.range(num_nodes), -1), [1, K])\n",
    "    cc = tf.argsort(dW, -1, direction='ASCENDING')[:, :K]\n",
    "    indices = tf.stack([tf.reshape(rr, -1), tf.reshape(cc, -1)], -1)\n",
    "    indices = tf.cast(indices, 'int64')\n",
    "    values = tf.gather_nd(dW, indices)\n",
    "    y = tf.SparseTensor(indices, values, dense_shape=[num_nodes, num_nodes])\n",
    "    y = tf.sparse.to_dense(tf.sparse.reorder(y), default_value=math.inf)\n",
    "    return y  # [my-node, k-node]\n",
    "\n",
    "\n",
    "def get_H_run_KNeighbors(adj,\n",
    "                         n_neighbors=5,\n",
    "                         num_loop=None,\n",
    "                         batch_size=1,\n",
    "                         verbose=False):\n",
    "    # 轉成 稀疏張量\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    adj = adj.toarray().astype('float32')\n",
    "    adj = tf.convert_to_tensor(adj)\n",
    "    dW = tf.sparse.from_dense(adj)\n",
    "    # 維持 對角線 元素存在 (補0)\n",
    "    dW = tf_sparse_add_zero_eye(dW)\n",
    "    # 計算 距離矩陣\n",
    "    dW = tf_sparse_dist_W(dW, num_loop, batch_size, verbose=verbose)\n",
    "    dW = tf.sparse.to_dense(dW, default_value=math.inf)\n",
    "    #================================================================\n",
    "    if verbose:\n",
    "        print(f'dW = \\n{dW}')\n",
    "    dW = tf_KNN_for_dW(dW, K=n_neighbors)\n",
    "    #================================================================\n",
    "    if verbose:\n",
    "        print(f'KNN={n_neighbors} => [my-node, k-node]\\n{dW}')\n",
    "    H = tf.linalg.matrix_transpose(dW)\n",
    "    H = tf.cast(tf.logical_not(tf.math.is_inf(H)), 'float32')\n",
    "    H = sp.coo_matrix(H.numpy())\n",
    "    if verbose:\n",
    "        print(f'H=\\n{H.toarray()}')\n",
    "    return H\n",
    "\n",
    "\n",
    "#==========#==========#==========#==========#==========#==========#==========#\n",
    "\n",
    "\n",
    "def get_H_run_RadiusNeighbors(adj,\n",
    "                              radius=None,\n",
    "                              num_loop=None,\n",
    "                              batch_size=None,\n",
    "                              verbose=False):\n",
    "    # 轉成 稀疏張量\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    adj = adj.toarray().astype('float32')\n",
    "    adj = tf.convert_to_tensor(adj)\n",
    "    dW = tf.sparse.from_dense(adj)\n",
    "    # 維持 對角線 元素存在 (補0)\n",
    "    dW = tf_sparse_add_zero_eye(dW)\n",
    "    # 計算 距離矩陣\n",
    "    dW = tf_sparse_dist_W(dW, num_loop, batch_size, verbose=verbose)\n",
    "    dW = tf.sparse.to_dense(dW, default_value=math.inf)\n",
    "    print(dW)\n",
    "    #================================================================\n",
    "    if verbose:\n",
    "        print(f'dW = \\n{dW}')\n",
    "    if radius is None:\n",
    "        H = tf.cast(tf.logical_not(tf.math.is_inf(dW)), 'float32')\n",
    "    else:\n",
    "        H = tf.cast(tf.less_equal(dW, radius), 'float32')\n",
    "    H = sp.coo_matrix(H.numpy())\n",
    "    if verbose:\n",
    "        print(f'H=\\n{H}')\n",
    "    return H\n",
    "\n",
    "\n",
    "#==========#==========#==========#==========#==========#==========#==========#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T15:31:35.446326Z",
     "start_time": "2021-06-17T15:31:35.354572Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  2.,  3.,  4.,  5., inf, inf, inf, inf],\n",
       "       [ 1.,  0.,  1.,  2.,  3.,  4., inf, inf, inf, inf],\n",
       "       [ 2.,  1.,  0.,  1.,  2.,  3., inf, inf, inf, inf],\n",
       "       [ 3.,  2.,  1.,  0.,  1.,  2., inf, inf, inf, inf],\n",
       "       [ 4.,  3.,  2.,  1.,  0.,  1., inf, inf, inf, inf],\n",
       "       [ 5.,  4.,  3.,  2.,  1.,  0., inf, inf, inf, inf],\n",
       "       [inf, inf, inf, inf, inf, inf,  0.,  1.,  2.,  3.],\n",
       "       [inf, inf, inf, inf, inf, inf,  1.,  0.,  1.,  2.],\n",
       "       [inf, inf, inf, inf, inf, inf,  2.,  1.,  0.,  1.],\n",
       "       [inf, inf, inf, inf, inf, inf,  3.,  2.,  1.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = get_adj([(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (6, 7), (7, 8), (8, 9)],\n",
    "            10).toarray()\n",
    "W = W.astype('float32')\n",
    "W = tf.convert_to_tensor(W)\n",
    "W = tf.sparse.from_dense(W)\n",
    "W = tf_sparse_add_zero_eye(W)  # 維持 對角線 元素存在\n",
    "\n",
    "tf.sparse.to_dense(tf_sparse_dist_W(W), default_value=math.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T15:32:46.813512Z",
     "start_time": "2021-06-17T15:32:46.729585Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  2.,  3.,  4.,  5., inf, inf, inf, inf],\n",
       "       [ 1.,  0.,  1.,  2.,  3.,  4., inf, inf, inf, inf],\n",
       "       [ 2.,  1.,  0.,  1.,  2.,  3., inf, inf, inf, inf],\n",
       "       [ 3.,  2.,  1.,  0.,  1.,  2., inf, inf, inf, inf],\n",
       "       [ 4.,  3.,  2.,  1.,  0.,  1., inf, inf, inf, inf],\n",
       "       [ 5.,  4.,  3.,  2.,  1.,  0., inf, inf, inf, inf],\n",
       "       [inf, inf, inf, inf, inf, inf,  0.,  1.,  2.,  3.],\n",
       "       [inf, inf, inf, inf, inf, inf,  1.,  0.,  1.,  2.],\n",
       "       [inf, inf, inf, inf, inf, inf,  2.,  1.,  0.,  1.],\n",
       "       [inf, inf, inf, inf, inf, inf,  3.,  2.,  1.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = get_adj([(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (6, 7), (7, 8), (8, 9)],\n",
    "            10).toarray()\n",
    "W = W.astype('float32')\n",
    "W = sp.coo_matrix(W)\n",
    "\n",
    "tf.sparse.to_dense(get_dW(W), default_value=math.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T15:59:44.242086Z",
     "start_time": "2021-06-17T15:59:44.168283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = get_adj([(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (6, 7), (7, 8), (8, 9)],\n",
    "            10).toarray()\n",
    "W = W.astype('float32')\n",
    "W = sp.coo_matrix(W)\n",
    "\n",
    "H = get_H_run_KNeighbors(W, n_neighbors=3)\n",
    "H.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T16:00:27.164132Z",
     "start_time": "2021-06-17T16:00:27.079334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.  1.  2.  3.  4.  5. inf inf inf inf]\n",
      " [ 1.  0.  1.  2.  3.  4. inf inf inf inf]\n",
      " [ 2.  1.  0.  1.  2.  3. inf inf inf inf]\n",
      " [ 3.  2.  1.  0.  1.  2. inf inf inf inf]\n",
      " [ 4.  3.  2.  1.  0.  1. inf inf inf inf]\n",
      " [ 5.  4.  3.  2.  1.  0. inf inf inf inf]\n",
      " [inf inf inf inf inf inf  0.  1.  2.  3.]\n",
      " [inf inf inf inf inf inf  1.  0.  1.  2.]\n",
      " [inf inf inf inf inf inf  2.  1.  0.  1.]\n",
      " [inf inf inf inf inf inf  3.  2.  1.  0.]], shape=(10, 10), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = get_adj([(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (6, 7), (7, 8), (8, 9)],\n",
    "            10).toarray()\n",
    "W = W.astype('float32')\n",
    "W = sp.coo_matrix(W)\n",
    "\n",
    "H = get_H_run_RadiusNeighbors(W, radius=3)\n",
    "H.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# from math_graph_knn import get_adj, get_dW\n",
    "# from math_graph_knn import get_adj, get_H_run_KNeighbors\n",
    "# from math_graph_knn import get_adj, get_H_run_RadiusNeighbors\n",
    "#==========#==========#==========#==========#==========#==========#==========#\n",
    "\n",
    "def get_adj(edges: list, num_nodes: int):\n",
    "    e_rows, e_cols = np.array(edges, dtype=np.int).transpose()\n",
    "    values = np.ones(shape=(len(e_rows), ), dtype=np.float32)\n",
    "    adj = sp.coo_matrix((values, (e_rows, e_cols)),\n",
    "                        shape=[num_nodes, num_nodes])\n",
    "    # triu adj --> adj\n",
    "    adj.setdiag(0)\n",
    "    bigger = adj.T > adj\n",
    "    adj = adj - adj.multiply(bigger) + adj.T.multiply(bigger)\n",
    "    return adj\n",
    "\n",
    "\n",
    "def np_adj_to_dW(adj):\n",
    "    dW = sp.coo_matrix(adj)\n",
    "    dW = dW.toarray().astype('float32')\n",
    "    dW[dW == 0] = float('inf')\n",
    "    np.fill_diagonal(dW, 0)\n",
    "    return dW\n",
    "\n",
    "\n",
    "def tf_dist_W(dW, num_loop=None, batch_size=None, verbose=False):\n",
    "    num_nodes = dW.shape[0]\n",
    "    # 計算估計 max loop\n",
    "    max_loop = int(np.ceil(np.log2(num_nodes)))\n",
    "    if num_loop is not None:\n",
    "        max_loop = min(num_loop, max_loop)\n",
    "    # 設定 預設 batch_size\n",
    "    if batch_size is None:\n",
    "        if num_nodes >= 1000:\n",
    "            batch_size = 10\n",
    "        else:\n",
    "            batch_size = num_nodes\n",
    "    if verbose:\n",
    "        print(f'max_loop={max_loop}, batch_size={batch_size}')\n",
    "    # 迭代 max_loop 次\n",
    "    for i_loop in range(max_loop):\n",
    "        dW_odd = dW\n",
    "        A = tf.expand_dims(dW, 2)  # [N,N,1]\n",
    "        B = tf.expand_dims(dW, 0)  # [1,N,N]\n",
    "        # 以 batch 方式計算 dW = tf.reduce_min(A+B, 1)\n",
    "        ys = []\n",
    "        for ia in range(0, num_nodes, batch_size):\n",
    "            # 依序抽取 batch_size 個\n",
    "            ib = ia + batch_size\n",
    "            if ib >= num_nodes:\n",
    "                ib = num_nodes\n",
    "            iw = A[ia:ib]  # [batch_size,N,1]\n",
    "            # 計算 batch_size 個\n",
    "            ys.append(tf.reduce_min(iw + B, 1))\n",
    "        dW = tf.concat(ys, 0)\n",
    "        # 檢查如果 dW 和 dW_odd 則 提前停止\n",
    "        if tf.math.reduce_all(tf.equal(dW, dW_odd)):\n",
    "            break\n",
    "        if verbose:\n",
    "            print(f'run {i_loop}/{max_loop}')\n",
    "            print(f'{dW}')\n",
    "    return dW\n",
    "\n",
    "#==========#==========#==========#==========#==========#==========#==========#\n",
    "\n",
    "\n",
    "def get_dW(adj, num_loop=None, batch_size=1, verbose=False):\n",
    "    dW = np_adj_to_dW(adj)  # [N,N]\n",
    "    dW = tf.convert_to_tensor(dW)\n",
    "    dW = tf_dist_W(dW, num_loop, batch_size, verbose=verbose)\n",
    "    return dW.numpy()\n",
    "\n",
    "\n",
    "#==========#==========#==========#==========#==========#==========#==========#\n",
    "\n",
    "def tf_KNN_for_dW(dW, K=3):\n",
    "    num_nodes = dW.shape[0]\n",
    "    rr = tf.tile(tf.expand_dims(tf.range(num_nodes), -1), [1, K])\n",
    "    cc = tf.argsort(dW, -1, direction='ASCENDING')[:, :K]\n",
    "    indices = tf.stack([tf.reshape(rr, -1), tf.reshape(cc, -1)], -1)\n",
    "    indices = tf.cast(indices, 'int64')\n",
    "    values = tf.gather_nd(dW, indices)\n",
    "    y = tf.SparseTensor(indices, values, dense_shape=[num_nodes, num_nodes])\n",
    "    y = tf.sparse.to_dense(tf.sparse.reorder(y), default_value=math.inf)\n",
    "    return y  # [my-node, k-node]\n",
    "\n",
    "\n",
    "def get_H_run_KNeighbors(adj, n_neighbors=5, num_loop=None, batch_size=1, verbose=False):\n",
    "    dW = np_adj_to_dW(adj)  # [N,N]\n",
    "    dW = tf.convert_to_tensor(dW)\n",
    "    dW = tf_dist_W(dW, num_loop, batch_size, verbose=verbose)\n",
    "    if verbose:\n",
    "        print(f'dW = \\n{dW}')\n",
    "    dW = tf_KNN_for_dW(dW, K=n_neighbors)\n",
    "    if verbose:\n",
    "        print(f'KNN={n_neighbors} => [my-node, k-node]\\n{dW}')\n",
    "    H = tf.linalg.matrix_transpose(dW)\n",
    "    H = tf.cast(tf.logical_not(tf.math.is_inf(H)), 'float32')\n",
    "    H = sp.coo_matrix(H.numpy())\n",
    "    if verbose:\n",
    "        print(f'H=\\n{H.toarray()}')\n",
    "    return H\n",
    "\n",
    "\n",
    "#==========#==========#==========#==========#==========#==========#==========#\n",
    "\n",
    "def get_H_run_RadiusNeighbors(adj, radius=None, num_loop=None, batch_size=None, verbose=False):\n",
    "    dW = np_adj_to_dW(adj)  # [N,N]\n",
    "    dW = tf.convert_to_tensor(dW)\n",
    "    dW = tf_dist_W(dW, num_loop, batch_size, verbose=verbose)\n",
    "    if verbose:\n",
    "        print(f'dW = \\n{dW}')\n",
    "    if radius is None:\n",
    "        H = tf.cast(tf.logical_not(tf.math.is_inf(dW)), 'float32')\n",
    "    else:\n",
    "        H = tf.cast(tf.less_equal(dW, radius), 'float32')\n",
    "    H = H.numpy()\n",
    "    if verbose:\n",
    "        print(f'H=\\n{H}')\n",
    "    return H\n",
    "\n",
    "\n",
    "#==========#==========#==========#==========#==========#==========#==========#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def tf_sparse_matmul_indices(sp_a, sp_b, num_split=1):\n",
    "    a_values = tf.ones_like(sp_a.values, dtype='int8')\n",
    "    b_values = tf.ones_like(sp_b.values, dtype='int8')\n",
    "    A = tf.sparse.SparseTensor(sp_a.indices, a_values, sp_a.shape)  # [M, P]\n",
    "    B = tf.sparse.SparseTensor(sp_b.indices, b_values, sp_b.shape)  # [P, N]\n",
    "    A = tf.sparse.expand_dims(A, -1)  # A [M, P, 1]\n",
    "    B = tf.sparse.expand_dims(B, 0)  # B [1, P, N]\n",
    "    Ys = []\n",
    "    for i, iA in enumerate(tf.sparse.split(A, num_split=num_split, axis=0)):\n",
    "        print(f'{i}/{num_split}')\n",
    "        # iA.values all = 1 # B.values all = 1\n",
    "        AA = tf.sparse.concat(2, [iA] * B.shape[2])  # set(AA)\n",
    "        BB = tf.sparse.concat(0, [B] * iA.shape[0])  # set(BB)\n",
    "        AB = tf.sparse.add(AA, BB)\n",
    "        AB = tf.sparse.map_values(tf.ones_like, AB)  # set(AA | BB)\n",
    "        A_ = tf.sparse.add(AB, BB * -1)  # set(AA) - set(AA ^ BB)\n",
    "        _B = tf.sparse.add(AB, AA * -1)  # set(BB) - set(AA ^ BB)\n",
    "        A_B = tf.sparse.add(A_, _B)  # set(AA | BB) - set(AA ^ BB)\n",
    "        _AB_ = tf.sparse.add(AB, A_B * -1)  # set(AA ^ BB)\n",
    "        iAB = tf.sparse.reduce_sum(_AB_, axis=1, output_is_sparse=True)\n",
    "        iAB = tf.cast(iAB, 'bool')\n",
    "        Ys.append(iAB)\n",
    "    return Ys\n",
    "    #Y = tf.concat(Ys, 0)\n",
    "    #Y = tf.sparse.from_dense(Y)\n",
    "    #Y = tf.sparse.map_values(tf.ones_like, Y)\n",
    "    #return Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
