{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 範例資料"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DADs.shape = (num_K, num_nodes, num_nodes)  #事先計算好 #非稀疏張量運算\n",
    "\n",
    "X.shape = (batch_size, num_nodes, num_Fin) #非稀疏張量運算\n",
    "\n",
    "W.shape = (num_K, num_Fin, num_Fout)\n",
    "\n",
    "b.shape = (num_Fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T16:21:01.062317Z",
     "start_time": "2021-05-09T16:20:58.389470Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj:\n",
      "[[0. 1. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n",
      "\n",
      "DADs: shape=(num_K, num_nodes, num_nodes)=(1, 5, 5) type=<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[[[0.5        0.4082483  0.         0.         0.        ]\n",
      "  [0.4082483  0.33333334 0.28867513 0.         0.        ]\n",
      "  [0.         0.28867513 0.25       0.35355338 0.35355338]\n",
      "  [0.         0.         0.35355338 0.5        0.        ]\n",
      "  [0.         0.         0.35355338 0.         0.5       ]]]\n",
      "\n",
      "X: shape=(batch_size, num_nodes, num_Fin)=(2, 5, 3) type=<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[[[ 0.  1.  2.]\n",
      "  [ 3.  4.  5.]\n",
      "  [ 6.  7.  8.]\n",
      "  [ 9. 10. 11.]\n",
      "  [12. 13. 14.]]\n",
      "\n",
      " [[15. 16. 17.]\n",
      "  [18. 19. 20.]\n",
      "  [21. 22. 23.]\n",
      "  [24. 25. 26.]\n",
      "  [27. 28. 29.]]]\n",
      "\n",
      "W: shape=(num_K, num_Fin, num_Fout)=(1, 3, 4) type=<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[[[ 0.  1.  2.  3.]\n",
      "  [ 4.  5.  6.  7.]\n",
      "  [ 8.  9. 10. 11.]]]\n",
      "\n",
      "b: shape=(num_Fout)=(4,) type=<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[0. 1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from math_graph import get_adj\n",
    "from math_graph import get_sp_DAD\n",
    "\n",
    "num_nodes = 5\n",
    "edges = [(0, 1), (1, 2), (2, 3), (2, 4)]\n",
    "# 產生 adj\n",
    "adj = get_adj(edges, num_nodes)\n",
    "print(f\"adj:\\n{adj.toarray()}\\n\")\n",
    "\n",
    "# 產生 DADs\n",
    "DAD = get_sp_DAD(adj).toarray()\n",
    "DAD = tf.convert_to_tensor(DAD, dtype='float32')\n",
    "DADs = tf.expand_dims(DAD, 0)\n",
    "print(f\"DADs: shape=(num_K, num_nodes, num_nodes)={DADs.shape} type={type(DADs)}\\n{DADs.numpy()}\\n\")\n",
    "\n",
    "batch_size = 2\n",
    "num_Fin = 3\n",
    "X = np.arange(batch_size*num_nodes*num_Fin).reshape([batch_size, num_nodes, num_Fin])\n",
    "X = tf.convert_to_tensor(X, dtype='float32')\n",
    "print(f\"X: shape=(batch_size, num_nodes, num_Fin)={X.shape} type={type(X)}\\n{X.numpy()}\\n\")\n",
    "\n",
    "num_Fout = 4\n",
    "num_K = DADs.shape[0]\n",
    "W = np.arange(num_Fin*num_Fout).reshape([num_K, num_Fin, num_Fout])\n",
    "W = tf.convert_to_tensor(W, dtype='float32')\n",
    "print(f\"W: shape=(num_K, num_Fin, num_Fout)={W.shape} type={type(W)}\\n{W.numpy()}\\n\")\n",
    "\n",
    "\n",
    "b = np.arange(num_Fout).reshape([num_Fout])\n",
    "b = tf.convert_to_tensor(b, dtype='float32')\n",
    "print(f\"b: shape=(num_Fout)={b.shape} type={type(b)}\\n{b.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 張量運算說明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T16:21:01.544525Z",
     "start_time": "2021-05-09T16:21:01.063315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: DADs=(num_K, num_nodes, #num_nodes) X=(batch_size, #num_nodes', num_Fin)\n",
      "shape: DADs=(1, 5, 5) X=(2, 5, 3)\n",
      "\n",
      "shape: DADs@X=DADsX=(batch_size, num_Fin, num_K, num_nodes)=(2, 3, 1, 5)\n",
      "[[[[ 1.2247449  2.732051   9.790647   6.6213202  8.121321 ]]\n",
      "\n",
      "  [[ 2.1329932  3.7623076 11.036428   7.4748735  8.974874 ]]\n",
      "\n",
      "  [[ 3.0412416  4.7925644 12.28221    8.328427   9.828427 ]]]\n",
      "\n",
      "\n",
      " [[[14.84847   18.185902  28.477375  19.424622  20.924622 ]]\n",
      "\n",
      "  [[15.756718  19.21616   29.723156  20.278175  21.778175 ]]\n",
      "\n",
      "  [[16.664967  20.246416  30.968937  21.13173   22.63173  ]]]]\n",
      "\n",
      "\n",
      "shape: DADsX=(batch_size, #num_Fin, #num_K, num_nodes) W=(#num_K, #num_Fin, num_Fout)\n",
      "shape: DADsX=(2, 3, 1, 5) W=(1, 3, 4)\n",
      "\n",
      "shape: DADsX@W=DADsXW=(batch_size, num_nodes, num_Fout)=(2, 5, 4)\n",
      "[[[ 32.861908  39.260887  45.659866  52.058846]\n",
      "  [ 53.389748  64.67667   75.96359   87.25052 ]\n",
      "  [142.4034   175.5127   208.62196  241.73125 ]\n",
      "  [ 96.52692  118.95154  141.37616  163.80078 ]\n",
      "  [114.52692  141.45154  168.37616  195.30078 ]]\n",
      "\n",
      " [[196.3466   243.61676  290.8869   338.15707 ]\n",
      "  [238.83597  296.48444  354.13293  411.7814  ]\n",
      "  [366.6441   455.8136   544.98303  634.15247 ]\n",
      "  [250.16653  311.00107  371.83557  432.6701  ]\n",
      "  [268.16653  333.50104  398.83557  464.1701  ]]]\n",
      "\n",
      "\n",
      "shape: DADsXW+b=(2, 5, 4)\n",
      "[[[ 32.861908  40.260887  47.659866  55.058846]\n",
      "  [ 53.389748  65.67667   77.96359   90.25052 ]\n",
      "  [142.4034   176.5127   210.62196  244.73125 ]\n",
      "  [ 96.52692  119.95154  143.37616  166.80078 ]\n",
      "  [114.52692  142.45154  170.37616  198.30078 ]]\n",
      "\n",
      " [[196.3466   244.61676  292.8869   341.15707 ]\n",
      "  [238.83597  297.48444  356.13293  414.7814  ]\n",
      "  [366.6441   456.8136   546.98303  637.15247 ]\n",
      "  [250.16653  312.00107  373.83557  435.6701  ]\n",
      "  [268.16653  334.50104  400.83557  467.1701  ]]]\n"
     ]
    }
   ],
   "source": [
    "# DADs @ X\n",
    "print(f\"shape: DADs=(num_K, num_nodes, #num_nodes) X=(batch_size, #num_nodes', num_Fin)\")\n",
    "print(f\"shape: DADs={DADs.shape} X={X.shape}\\n\")\n",
    "DADsX = tf.tensordot(X, DADs, axes=([1], [-1]))\n",
    "print(f\"shape: DADs@X=DADsX=(batch_size, num_Fin, num_K, num_nodes)={DADsX.shape}\\n{DADsX.numpy()}\\n\\n\")\n",
    "\n",
    "# DADs@X @ W\n",
    "print(f\"shape: DADsX=(batch_size, #num_Fin, #num_K, num_nodes) W=(#num_K, #num_Fin, num_Fout)\")\n",
    "print(f\"shape: DADsX={DADsX.shape} W={W.shape}\\n\")\n",
    "DADsXW = tf.tensordot(DADsX, W, axes=([1, 2], [1, 0]))\n",
    "print(f\"shape: DADsX@W=DADsXW=(batch_size, num_nodes, num_Fout)={DADsXW.shape}\\n{DADsXW.numpy()}\\n\\n\")\n",
    "\n",
    "# DADs@X@W + b\n",
    "output = tf.add(DADsXW, b)\n",
    "print(f\"shape: DADsXW+b={output.shape}\\n{output.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphConvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T16:21:01.560180Z",
     "start_time": "2021-05-09T16:21:01.546444Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaseDense(tf.keras.layers.Dense):\n",
    "    def add_weight_kernel(self, shape, name='kernel', trainable=True):\n",
    "        return self.add_weight(name=name,\n",
    "                               shape=shape,\n",
    "                               trainable=trainable,\n",
    "                               initializer=self.kernel_initializer,\n",
    "                               regularizer=self.kernel_regularizer,\n",
    "                               constraint=self.kernel_constraint,\n",
    "                               dtype=self.dtype)\n",
    "\n",
    "    def add_weight_bias(self, shape, name='bias', trainable=True):\n",
    "        return self.add_weight(name=name,\n",
    "                               shape=shape,\n",
    "                               trainable=trainable,\n",
    "                               initializer=self.bias_initializer,\n",
    "                               regularizer=self.bias_regularizer,\n",
    "                               constraint=self.bias_constraint,\n",
    "                               dtype=self.dtype)\n",
    "\n",
    "class GraphConvs(BaseDense):\n",
    "    def __init__(self, units, DADs, name=None, **kwargs):\n",
    "        super(GraphConvs, self).__init__(units=units, name=name, **kwargs)\n",
    "        self.DADs = tf.convert_to_tensor(DADs)\n",
    "        self.num_K = len(DADs)  # K\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.num_Fin = input_shape[-1]  # Fin\n",
    "        self.num_Fout = self.units  # Fout\n",
    "        self.kernel = self.add_weight_kernel([self.num_K, self.num_Fin, self.num_Fout])\n",
    "        self.bias = self.add_weight_bias([self.num_Fout,]) if self.use_bias else None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X = tf.tensordot(inputs, self.DADs, axes=([1], [-1]))\n",
    "        X = tf.tensordot(X, self.kernel, axes=([1, 2], [1, 0]))\n",
    "        if self.use_bias:\n",
    "            X = tf.add(X, self.bias)\n",
    "        outputs = self.activation(X)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T16:21:01.591335Z",
     "start_time": "2021-05-09T16:21:01.562176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 4), dtype=float32, numpy=\n",
       "array([[[ 4.8153954 ,  3.1498032 ,  2.5675948 , -0.09882069],\n",
       "        [ 8.212198  ,  4.9054947 ,  4.0464797 , -0.4879012 ],\n",
       "        [23.215256  , 12.369419  , 10.371268  , -2.4055085 ],\n",
       "        [15.728307  ,  8.388839  ,  7.032632  , -1.6238561 ],\n",
       "        [18.800213  ,  9.877428  ,  8.299372  , -2.0436625 ]],\n",
       "\n",
       "       [[32.715935  , 16.669893  , 14.072742  , -3.9117055 ],\n",
       "        [39.860725  , 20.241793  , 17.097158  , -4.8129864 ],\n",
       "        [61.484512  , 30.913998  , 26.152088  , -7.6353817 ],\n",
       "        [41.948673  , 21.094748  , 17.844938  , -5.2071285 ],\n",
       "        [45.020576  , 22.583336  , 19.11168   , -5.626935  ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from layer_gconv import GraphConvs\n",
    "\n",
    "## 產生 adj  #使用 無向邊 建構\n",
    "# adj = get_adj(edges, num_nodes)\n",
    "\n",
    "## 產生 DADs\n",
    "# DAD = get_sp_DAD(adj).toarray()\n",
    "# DAD = tf.convert_to_tensor(DAD, dtype='float32')\n",
    "# DADs = tf.expand_dims(DAD, 0)\n",
    "\n",
    "GraphConvs(units=num_Fout, DADs=DADs, use_bias=True)(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
